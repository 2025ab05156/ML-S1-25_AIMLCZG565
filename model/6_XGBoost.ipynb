{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc861936",
   "metadata": {},
   "source": [
    "# XGBoost (Extreme Gradient Boosting) Classifier - Credit Approval Classification\n",
    "\n",
    "This notebook implements an XGBoost Gradient Boosting Classifier for binary classification of credit approval.\n",
    "\n",
    "**Dataset:** UCI Student Performance (ID: 320)\n",
    "- Total Samples: 649 students\n",
    "- Features: 33 (school, age, study_time, failures, family_size, parent education, etc.)\n",
    "- Target: Final grade classification (20 classes: grades 0-19)\n",
    "- Training Set: 519 samples (80%)\n",
    "- Testing Set: 130 samples (20%)\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "1. Accuracy\n",
    "2. AUC Score\n",
    "3. Precision\n",
    "4. Recall\n",
    "5. F1 Score\n",
    "6. Matthews Correlation Coefficient (MCC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57be12b",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, roc_auc_score, precision_score,\n",
    "    recall_score, f1_score, matthews_corrcoef,\n",
    "    confusion_matrix, classification_report, roc_curve, auc\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646b1de",
   "metadata": {},
   "source": [
    "## 2. Load Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Credit Approval Dataset - Using synthetic dataset generation\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate synthetic credit approval dataset\n",
    "print(\"Generating synthetic credit approval dataset...\")\n",
    "X_synthetic, y_synthetic = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=15,\n",
    "    n_informative=10,\n",
    "    n_redundant=3,\n",
    "    n_clusters_per_class=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create feature names\n",
    "feature_names = [f'Feature_{i+1}' for i in range(X_synthetic.shape[1])]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X_synthetic, columns=feature_names)\n",
    "df['Approval'] = y_synthetic\n",
    "\n",
    "print(f\"✅ Synthetic dataset created successfully! Shape: {df.shape}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nData Types:\\n{df.dtypes}\")\n",
    "print(f\"\\nMissing Values:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nTarget Distribution:\\n{df.iloc[:, -1].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b875ffdb",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e38c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy\n",
    "df_processed = df.copy()\n",
    "\n",
    "# Identify target column name (last column)\n",
    "target_col_name = df_processed.columns[-1]\n",
    "\n",
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "df_processed = df_processed.dropna()\n",
    "print(f\"Shape after dropping NaN: {df_processed.shape}\")\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = df_processed.select_dtypes(include=['int64', 'float64', 'int32']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical columns: {categorical_cols}\")\n",
    "print(f\"Numerical columns: {numerical_cols}\")\n",
    "\n",
    "# Encode categorical variables (including target if it's categorical)\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_processed[col] = le.fit_transform(df_processed[col])\n",
    "    label_encoders[col] = le\n",
    "    if col == target_col_name:\n",
    "        print(f\"Encoded target column: {col} with classes: {le.classes_.tolist()}\")\n",
    "    else:\n",
    "        print(f\"Encoded {col}\")\n",
    "\n",
    "print(\"\\nData preprocessing completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2747bf6",
   "metadata": {},
   "source": [
    "## 4. Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a88c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target column\n",
    "target_col = 'Approval' if 'Approval' in df_processed.columns else df_processed.columns[-1]\n",
    "\n",
    "# Separate features and target\n",
    "X = df_processed.drop(columns=[target_col])\n",
    "y = df_processed[target_col]\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target column: {target_col}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(y.value_counts())\n",
    "print(f\"\\nFeature names:\")\n",
    "print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0503bfe7",
   "metadata": {},
   "source": [
    "## 5. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")\n",
    "print(f\"\\nTraining target distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"\\nData split completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853fd8d",
   "metadata": {},
   "source": [
    "## 6. Train XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d2bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the XGBoost Classifier\n",
    "print(\"Training XGBoost Classifier...\")\n",
    "\n",
    "# Encode target to contiguous classes (0, 1, 2, ...) to avoid XGBoost class mismatch issues\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_target = LabelEncoder()\n",
    "y_train_encoded = le_target.fit_transform(y_train)\n",
    "y_test_encoded = le_target.transform(y_test)\n",
    "\n",
    "# Create a fresh XGBoost model\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    eval_metric='mlogloss',\n",
    "    verbosity=0,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "print(\"✅ Model training completed!\")\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"Number of boosting rounds: {xgb_model.n_estimators}\")\n",
    "print(f\"Max depth: {xgb_model.max_depth}\")\n",
    "print(f\"Learning rate: {xgb_model.learning_rate}\")\n",
    "print(f\"Number of features: {xgb_model.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c63d7",
   "metadata": {},
   "source": [
    "## 7. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred_encoded = xgb_model.predict(X_test)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "y_pred = le_target.inverse_transform(y_pred_encoded)\n",
    "\n",
    "print(\"Predictions made on test set!\")\n",
    "print(f\"\\nFirst 10 predictions:\")\n",
    "print(y_pred[:10])\n",
    "print(f\"\\nFirst 10 prediction probabilities:\")\n",
    "print(y_pred_proba[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacbd0d1",
   "metadata": {},
   "source": [
    "## 8. Calculate Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eb1c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate all evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba[:, 1])\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"XGBOOST - EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"AUC Score: {auc_score:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"MCC Score: {mcc:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - XGBoost')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# ROC Curve for binary classification\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "axes[1].plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve - XGBoost')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f36052",
   "metadata": {},
   "source": [
    "## 9. Additional Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc465128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff3ff9",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking:\")\n",
    "print(feature_importance)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='darkblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.title('XGBoost - Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 most important features:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1fcf9b",
   "metadata": {},
   "source": [
    "## 11. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afebba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional visualization with different styling\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Confusion Matrix Heatmap with blue colors\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix - XGBoost')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# ROC Curve for binary classification with better styling\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[1].plot(fpr, tpr, color='darkblue', lw=3, label=f'XGBoost (AUC = {roc_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', lw=2, alpha=0.7, label='Random Classifier')\n",
    "axes[1].fill_between(fpr, tpr, alpha=0.3, color='darkblue')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curve - XGBoost Classifier')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAdditional visualizations complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1d23e7",
   "metadata": {},
   "source": [
    "## 12. Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d859e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"XGBOOST CLASSIFIER MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel Type: XGBoost Gradient Boosting Classifier\")\n",
    "print(f\"Number of Boosting Rounds: {xgb_model.n_estimators}\")\n",
    "print(f\"Max Depth: {xgb_model.max_depth}\")\n",
    "print(f\"Learning Rate: {xgb_model.learning_rate}\")\n",
    "print(f\"Training Samples: {X_train.shape[0]}\")\n",
    "print(f\"Testing Samples: {X_test.shape[0]}\")\n",
    "print(f\"Number of Features: {X_train.shape[1]}\")\n",
    "print(f\"\\nKey Metrics:\")\n",
    "print(f\"  - Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  - AUC Score: {auc_score:.4f}\")\n",
    "print(f\"  - F1 Score:  {f1:.4f}\")\n",
    "print(f\"\\nTop 3 Most Important Features:\")\n",
    "for idx, row in feature_importance.head(3).iterrows():\n",
    "    print(f\"  - {row['Feature']}: {row['Importance']:.4f}\")\n",
    "print(f\"\\nModel Status: ✅ Training Complete\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
